# H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng H·ªá Th·ªëng Log Anomaly Detection

**Phi√™n b·∫£n:** 1.0 (Fixed)  
**Ng√†y c·∫≠p nh·∫≠t:** 2025-12-16  
**Tr·∫°ng th√°i:** ‚úÖ ƒê√£ s·ª≠a t·∫•t c·∫£ l·ªói nghi√™m tr·ªçng

---

## üìã M·ª•c L·ª•c

1. [Y√™u C·∫ßu H·ªá Th·ªëng](#1-y√™u-c·∫ßu-h·ªá-th·ªëng)
2. [C√†i ƒê·∫∑t](#2-c√†i-ƒë·∫∑t)
3. [Workflow Ho√†n Ch·ªânh](#3-workflow-ho√†n-ch·ªânh)
4. [S·ª≠ D·ª•ng Server](#4-s·ª≠-d·ª•ng-server)
5. [S·ª≠ D·ª•ng Client](#5-s·ª≠-d·ª•ng-client)
6. [API Endpoints](#6-api-endpoints)
7. [Switching Models](#7-switching-models)
8. [Troubleshooting](#8-troubleshooting)

---

## 1. Y√™u C·∫ßu H·ªá Th·ªëng

### Python Backend
- **Python**: 3.8 ho·∫∑c m·ªõi h∆°n (ƒë√£ test v·ªõi 3.13.9)
- **OS**: Windows/Linux/macOS
- **RAM**: T·ªëi thi·ªÉu 4GB
- **Storage**: ~2GB cho models v√† data

### .NET Client
- **.NET SDK**: 8.0 ho·∫∑c m·ªõi h∆°n
- **OS**: Windows (WinForms)

---

## 2. C√†i ƒê·∫∑t

### B∆∞·ªõc 1: C√†i ƒê·∫∑t Python Dependencies

```powershell
# T·∫°i th∆∞ m·ª•c g·ªëc c·ªßa project
cd p:\Rust\LogDetection

# C√†i ƒë·∫∑t c√°c packages c·∫ßn thi·∫øt
pip install -r requirements.txt
```

**Ki·ªÉm tra c√†i ƒë·∫∑t:**
```powershell
python -c "import torch; import fastapi; import drain3; print('‚úÖ All packages installed')"
```

### B∆∞·ªõc 2: C√†i ƒê·∫∑t .NET Client (Optional)

```powershell
cd client
dotnet restore
dotnet build
```

---

## 3. Workflow Ho√†n Ch·ªânh

### üîÑ Pipeline X·ª≠ L√Ω D·ªØ Li·ªáu

```
Raw Logs (HDFS_2k.log)
    ‚Üì
[1. Parse] ‚Üí HDFS_structured.csv + drain3_state.bin
    ‚Üì
[2. Preprocess] ‚Üí session_data.pkl
    ‚Üì
[3. Train] ‚Üí transformer/lstm/cnn_model.pt (ƒê√É C√ì S·∫¥N)
    ‚Üì
[4. Server] ‚Üí FastAPI Server (localhost:8000)
    ‚Üì
[5. Client] ‚Üí .NET WinForms / API Calls
```

---

### B∆∞·ªõc 1: Parse Raw Logs

**M·ª•c ƒë√≠ch:** Chuy·ªÉn ƒë·ªïi raw logs th√†nh structured format v√† extract templates

```powershell
# Parse HDFS logs
python parsers\drain.py

# Ho·∫∑c s·ª≠ d·ª•ng main.py
python main.py parse data\HDFS\HDFS_2k.log
```

**Output:**
- ‚úÖ `data_processed/HDFS/HDFS_structured.csv` - Structured logs v·ªõi BlockId, EventTemplate
- ‚úÖ `parsers/drain3_state.bin` - Drain3 clustering state

**Ki·ªÉm tra:**
```powershell
# Xem 10 d√≤ng ƒë·∫ßu
Get-Content data_processed\HDFS\HDFS_structured.csv -Head 10
```

---

### B∆∞·ªõc 2: Preprocess Data

**M·ª•c ƒë√≠ch:** T·∫°o sliding windows v√† vocabulary cho training/inference

```powershell
python detection\preprocess_data.py

# Ho·∫∑c
python main.py preprocess
```

**Output:**
- ‚úÖ `data_processed/HDFS/session_data.pkl` - Training/test data v·ªõi:
  - X_train, X_test (sliding windows)
  - y_train_anomaly, y_test_anomaly (labels)
  - log2id, id2log (vocabulary)
  - vocab_size, window_size (metadata)

**Ki·ªÉm tra:**
```powershell
python -c "import pickle; data=pickle.load(open('data_processed/HDFS/session_data.pkl','rb')); print(f'Vocab: {data[\"vocab_size\"]}, Windows: {len(data[\"X_train\"])}')"
```

---

### B∆∞·ªõc 3: Train Models (OPTIONAL - ƒê√£ c√≥ models)

H·ªá th·ªëng ƒë√£ c√≥ 3 models ƒë√£ train s·∫µn:
- ‚úÖ `detection/models/transformer_model.pt` (755 KB)
- ‚úÖ `detection/models/lstm_model.pt` (384 KB)
- ‚úÖ `detection/models/cnn_model.pt` (66 KB)

**N·∫øu mu·ªën train l·∫°i:**

#### Train Transformer
```powershell
python train\train_transformer.py --model transformer --epochs 100 --batch_size 1024 --lr 0.01
```

#### Train LSTM
```powershell
python train\lstm.py --epoches 100 --batch_size 1024 --learning_rate 0.01 --hidden_size 100 --num_directions 2
```

#### Train CNN
```powershell
python train\cnn.py --epoches 100 --batch_size 1024 --learning_rate 0.01 --hidden_size 100 --kernel_sizes 2,3,4
```

**Ho·∫∑c d√πng main.py:**
```powershell
python main.py train --model transformer --epochs 100
python main.py train --model lstm --epochs 100
python main.py train --model cnn --epochs 100
```

---

## 4. S·ª≠ D·ª•ng Server

### Kh·ªüi ƒê·ªông Server

```powershell
# Method 1: Tr·ª±c ti·∫øp
python communication\server.py

# Method 2: Qua main.py
python main.py server --host 0.0.0.0 --port 8000

# Method 3: V·ªõi uvicorn
uvicorn communication.server:app --host 0.0.0.0 --port 8000 --reload
```

**Server s·∫Ω startup v√†:**
1. ‚úÖ Load Drain3 state t·ª´ `parsers/drain3_state.bin`
2. ‚úÖ Load vocabulary t·ª´ `data_processed/HDFS/session_data.pkl`
3. ‚úÖ Load Transformer model (default)
4. ‚úÖ Load ground truth labels
5. ‚úÖ Start listening t·∫°i `http://localhost:8000`

**Ki·ªÉm tra server:**
```powershell
# Trong terminal kh√°c
curl http://localhost:8000/health

# Ho·∫∑c tr√™n browser
# M·ªü: http://localhost:8000/docs (FastAPI Swagger UI)
```

**Expected output:**
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

---

## 5. S·ª≠ D·ª•ng Client

### Method 1: .NET WinForms Client

```powershell
cd client
dotnet run
```

**Giao di·ªán Main Form:**
1. **Model Selection:** Ch·ªçn Transformer/CNN/LSTM
2. **New Log Uploader Client:** M·ªü form upload logs
3. **Open Server Monitor:** M·ªü form monitor metrics

**Log Uploader Form:**
1. Click "Upload Log File"
2. Ch·ªçn file log (v√≠ d·ª•: `data/HDFS/HDFS_2k.log`)
3. Logs s·∫Ω ƒë∆∞·ª£c g·ª≠i l√™n server t·ª´ng d√≤ng
4. Xem progress v√† results real-time

**Server Monitor Form:**
- Hi·ªÉn th·ªã blocks ƒë∆∞·ª£c process
- Metrics: Accuracy, Precision, Recall, F1
- Confusion matrix: TP, FP, TN, FN
- Auto-refresh m·ªói 5 gi√¢y

### Method 2: Python Script

```python
import requests

# Send single log line
response = requests.post(
    "http://localhost:8000/process_line",
    json={
        "line": "081109 203518 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906",
        "client_id": 1,
        "model_type": "transformer"
    }
)
print(response.json())
```

### Method 3: cURL

```powershell
# Process a log line
curl -X POST "http://localhost:8000/process_line" `
  -H "Content-Type: application/json" `
  -d '{\"line\": \"081109 203518 143 INFO dfs.DataNode: Receiving block blk_123\", \"client_id\": 1}'

# Get blocks
curl http://localhost:8000/blocks

# Get metrics
curl http://localhost:8000/metrics
```

---

## 6. API Endpoints

### Core Endpoints

#### GET `/health`
**M√¥ t·∫£:** Health check server

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

#### GET `/current_model`
**M√¥ t·∫£:** Xem model hi·ªán t·∫°i

**Response:**
```json
{
  "model_type": "transformer",
  "model_loaded": true,
  "vocab_size": 30,
  "window_size": 30
}
```

#### POST `/process_line`
**M√¥ t·∫£:** X·ª≠ l√Ω m·ªôt log line

**Request:**
```json
{
  "line": "081109 203518 143 INFO dfs.DataNode: Receiving block blk_123",
  "client_id": 1,
  "model_type": "transformer"
}
```

**Response:**
```json
{
  "result": "Processed: (081109 203518...) with template (...) from block (blk_123) (Client ID: 1)\nPrediction for block (blk_123): (normal)"
}
```

#### POST `/predict`
**M√¥ t·∫£:** Predict anomaly cho log line

**Request:**
```json
{
  "log_line": "081109 203518 143 INFO dfs.DataNode: Receiving block blk_123",
  "block_id": null
}
```

**Response:**
```json
{
  "status": "Normal",
  "confidence": 0.95,
  "block_id": "blk_123",
  "event_id": "E5"
}
```

#### GET `/blocks`
**M√¥ t·∫£:** L·∫•y danh s√°ch blocks

**Response:**
```json
{
  "blocks": [
    {
      "block_id": "blk_123",
      "log_count": 15,
      "last_log": "Receiving block...",
      "status": "normal",
      "client_ids": [1]
    }
  ],
  "total_log_count": 100,
  "total_block_count": 10,
  "last_updated": "2025-12-16 22:30:00"
}
```

#### GET `/metrics`
**M√¥ t·∫£:** L·∫•y accuracy metrics

**Response:**
```json
{
  "accuracy": 0.9545,
  "precision": 0.9200,
  "recall": 0.9100,
  "f1_score": 0.9150,
  "tp": 91,
  "fp": 8,
  "tn": 850,
  "fn": 9,
  "last_updated": "2025-12-16 22:30:00"
}
```

#### POST `/reset`
**M√¥ t·∫£:** Reset t·∫•t c·∫£ sessions

**Response:**
```json
{
  "status": "reset",
  "message": "All sessions cleared"
}
```

---

## 7. Switching Models

### ‚ú® NEW FEATURE: Dynamic Model Switching

B·∫°n c√≥ th·ªÉ switch gi·ªØa 3 models **KH√îNG C·∫¶N restart server**!

### Method 1: API Call

```powershell
# Switch to CNN
curl -X POST "http://localhost:8000/switch_model?model_type=cnn"

# Switch to LSTM
curl -X POST "http://localhost:8000/switch_model?model_type=lstm"

# Switch to Transformer
curl -X POST "http://localhost:8000/switch_model?model_type=transformer"
```

**Response:**
```json
{
  "status": "success",
  "model": "cnn",
  "message": "Switched to cnn model"
}
```

### Method 2: Python

```python
import requests

response = requests.post(
    "http://localhost:8000/switch_model",
    params={"model_type": "lstm"}
)
print(response.json())
```

### Method 3: Client (TODO)

Trong .NET client, b·∫°n c√≥ th·ªÉ th√™m button ƒë·ªÉ call API n√†y.

---

## 8. Troubleshooting

### ‚ùå Error: "Model not found"

**Nguy√™n nh√¢n:** Model file kh√¥ng t·ªìn t·∫°i

**Gi·∫£i ph√°p:**
```powershell
# Ki·ªÉm tra models
ls detection\models\*.pt

# N·∫øu thi·∫øu, train l·∫°i
python train\train_transformer.py --model transformer --epochs 10
```

### ‚ùå Error: "KeyError: 'BlockId'"

**Nguy√™n nh√¢n:** File CSV kh√¥ng c√≥ c·ªôt BlockId (ƒë√£ s·ª≠a)

**Gi·∫£i ph√°p:**
```powershell
# Parse l·∫°i logs v·ªõi version m·ªõi
python parsers\drain.py

# Sau ƒë√≥ preprocess l·∫°i
python detection\preprocess_data.py
```

### ‚ùå Error: "Server connection failed"

**Nguy√™n nh√¢n:** Server ch∆∞a ch·∫°y ho·∫∑c port b·ªã block

**Gi·∫£i ph√°p:**
```powershell
# Ki·ªÉm tra server ƒëang ch·∫°y
netstat -ano | findstr :8000

# Restart server
python communication\server.py
```

### ‚ùå Error: "Duplicate template parsing"

**Tr·∫°ng th√°i:** ‚úÖ ƒê√É S·ª¨A

L·ªói n√†y ƒë√£ ƒë∆∞·ª£c fix - server kh√¥ng c√≤n parse template 2 l·∫ßn.

### ‚ùå Error: "Inconsistent window padding"

**Tr·∫°ng th√°i:** ‚úÖ ƒê√É S·ª¨A

Inference gi·ªù ƒë√£ s·ª≠ d·ª•ng sliding windows gi·ªëng nh∆∞ training.

---

## üìä Example Workflow

### Scenario: Upload v√† ph√¢n t√≠ch file log

```powershell
# 1. Start server
python communication\server.py

# Trong terminal kh√°c:

# 2. Parse logs (n·∫øu ch∆∞a c√≥)
python parsers\drain.py

# 3. Process logs
curl -X POST "http://localhost:8000/process_line" `
  -H "Content-Type: application/json" `
  -d '{\"line\": \"081109 203518 143 INFO dfs.DataNode: Receiving block blk_-1608999687919862906\", \"client_id\": 1}'

# 4. Check metrics
curl http://localhost:8000/metrics

# 5. Switch to CNN model
curl -X POST "http://localhost:8000/switch_model?model_type=cnn"

# 6. Process more logs v·ªõi CNN
curl -X POST "http://localhost:8000/process_line" `
  -H "Content-Type: application/json" `
  -d '{\"line\": \"081109 203520 148 INFO dfs.DataNode: PacketResponder 1\", \"client_id\": 1}'

# 7. Get blocks
curl http://localhost:8000/blocks
```

---

## üéØ Best Practices

### 1. Workflow Chu·∫©n
```
Parse ‚Üí Preprocess ‚Üí (Train) ‚Üí Start Server ‚Üí Use Client/API
```

### 2. Model Selection
- **Transformer:** T·ªët nh·∫•t cho accuracy (~26K params)
- **LSTM:** Balance gi·ªØa speed v√† accuracy (~95K params)
- **CNN:** Nhanh nh·∫•t, accuracy v·∫´n t·ªët (~15K params)

### 3. Performance Tips
- S·ª≠ d·ª•ng batch processing cho nhi·ªÅu logs
- Switch model d·ª±a tr√™n workload
- Monitor memory usage v·ªõi nhi·ªÅu sessions

### 4. Production Deployment
- S·ª≠ d·ª•ng `--reload` cho development
- S·ª≠ d·ª•ng Gunicorn/Uvicorn workers cho production
- Implement Redis cho session storage (nhi·ªÅu workers)
- Add authentication cho API endpoints

---

## üìù Changelog

### Version 1.0 (2025-12-16) - Fixed Release

**üî¥ CRITICAL FIXES:**
1. ‚úÖ Fixed duplicate template parsing
2. ‚úÖ Fixed missing BlockId column
3. ‚úÖ Fixed model type mismatch
4. ‚úÖ Fixed inconsistent window padding

**üü° IMPROVEMENTS:**
5. ‚úÖ Centralized Drain3 configuration
6. ‚úÖ Added comprehensive error handling
7. ‚úÖ Added model validation on startup

**‚ú® NEW FEATURES:**
8. ‚úÖ Dynamic model switching without restart
9. ‚úÖ `/switch_model` endpoint
10. ‚úÖ `/current_model` endpoint
11. ‚úÖ Sliding window predictions

---

## üÜò H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, ki·ªÉm tra:

1. **Log files:** Server s·∫Ω print errors ra console
2. **FastAPI docs:** http://localhost:8000/docs
3. **Health check:** http://localhost:8000/health
4. **Review:** `LOGIC_ERRORS_REPORT.md` - Danh s√°ch c√°c l·ªói ƒë√£ s·ª≠a

---

## üéì T√≥m T·∫Øt C√°c L·ªánh Quan Tr·ªçng

```powershell
# C√†i ƒë·∫∑t
pip install -r requirements.txt

# Parse logs
python parsers\drain.py

# Preprocess
python detection\preprocess_data.py

# Start server
python communication\server.py

# Test health
curl http://localhost:8000/health

# Switch model
curl -X POST "http://localhost:8000/switch_model?model_type=cnn"

# Process log
curl -X POST "http://localhost:8000/process_line" -H "Content-Type: application/json" -d '{\"line\": \"your log here\"}'

# Get metrics
curl http://localhost:8000/metrics
```

---

**H·ªá th·ªëng gi·ªù ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng! üöÄ**
