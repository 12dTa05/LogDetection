# BÃ¡o CÃ¡o Sá»­a ÄÆ°á»ng Dáº«n - Path Fixes Report

**NgÃ y:** 2025-12-17  
**Má»¥c Ä‘Ã­ch:** Chuáº©n hÃ³a táº¥t cáº£ Ä‘Æ°á»ng dáº«n file trong há»‡ thá»‘ng Ä‘á»ƒ hoáº¡t Ä‘á»™ng Ä‘Ãºng trÃªn Linux

---

## ğŸ“‹ Tá»•ng Quan

ÄÃ£ sá»­a **6 files** vá»›i tá»•ng cá»™ng **7 thay Ä‘á»•i** vá» Ä‘Æ°á»ng dáº«n Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n vÃ  tÆ°Æ¡ng thÃ­ch vá»›i cáº¥u trÃºc thÆ° má»¥c thá»±c táº¿.

### Váº¥n Äá» ChÃ­nh

Há»‡ thá»‘ng cÃ³ cÃ¡c Ä‘Æ°á»ng dáº«n trá» Ä‘áº¿n thÆ° má»¥c `data_processed/HDFS/` vÃ  `data/HDFS/` nhÆ°ng thá»±c táº¿:
- âœ… ThÆ° má»¥c `data_processed/` tá»“n táº¡i (nhÆ°ng rá»—ng)
- âœ… ThÆ° má»¥c `data/` tá»“n táº¡i vá»›i file `anomaly_label.csv`
- âŒ ThÆ° má»¥c con `HDFS/` **KHÃ”NG** tá»“n táº¡i trong cáº£ hai

---

## ğŸ”§ Chi Tiáº¿t CÃ¡c Thay Äá»•i

### 1. **communication/server.py** (2 thay Ä‘á»•i)

#### Thay Ä‘á»•i 1: ÄÆ°á»ng dáº«n data_path (Line 260)
```python
# TRÆ¯á»šC:
data_path = os.path.join(project_root, 'data_processed', 'HDFS', 'session_data.pkl')

# SAU:
data_path = os.path.join(project_root, 'data_processed', 'session_data.pkl')
```

#### Thay Ä‘á»•i 2: ÄÆ°á»ng dáº«n label_path (Line 261 vÃ  534)
```python
# TRÆ¯á»šC:
label_path = os.path.join(project_root, 'data', 'HDFS', 'anomaly_label.csv')

# SAU:
label_path = os.path.join(project_root, 'data', 'anomaly_label.csv')
```

**LÃ½ do:** File `anomaly_label.csv` náº±m trá»±c tiáº¿p trong `data/`, khÃ´ng cÃ³ thÆ° má»¥c con `HDFS/`

---

### 2. **detection/preprocess_data.py** (1 thay Ä‘á»•i)

#### ÄÆ°á»ng dáº«n output_path (Line 179)
```python
# TRÆ¯á»šC: (Ä‘Ã£ Ä‘Ãºng, chá»‰ xÃ³a comment)
label_path = os.path.join(project_root, 'data', 'anomaly_label.csv')  # Updated path

# SAU:
label_path = os.path.join(project_root, 'data', 'anomaly_label.csv')
```

**LÃ½ do:** LÃ m sáº¡ch code, xÃ³a comment khÃ´ng cáº§n thiáº¿t

---

### 3. **main.py** (1 thay Ä‘á»•i)

#### ÄÆ°á»ng dáº«n output_dir (Line 43)
```python
# TRÆ¯á»šC:
output_dir = os.path.join(project_root, 'data_processed', 'HDFS')

# SAU:
output_dir = os.path.join(project_root, 'data_processed')
```

**LÃ½ do:** KhÃ´ng cáº§n táº¡o thÆ° má»¥c con `HDFS/`, lÆ°u trá»±c tiáº¿p vÃ o `data_processed/`

---

### 4. **train/train_transformer.py** (1 thay Ä‘á»•i)

#### ÄÆ°á»ng dáº«n máº·c Ä‘á»‹nh --data (Line 188)
```python
# TRÆ¯á»šC:
parser.add_argument('--data', type=str, default='data_processed/HDFS/session_data.pkl')

# SAU:
parser.add_argument('--data', type=str, default='data_processed/session_data.pkl')
```

**LÃ½ do:** File `session_data.pkl` sáº½ Ä‘Æ°á»£c lÆ°u trá»±c tiáº¿p trong `data_processed/`

---

### 5. **train/lstm.py** (1 thay Ä‘á»•i)

#### ÄÆ°á»ng dáº«n data_path (Line 44)
```python
# TRÆ¯á»šC:
data_path = os.path.join(project_root, 'data_processed', 'HDFS', 'session_data.pkl')

# SAU:
data_path = os.path.join(project_root, 'data_processed', 'session_data.pkl')
```

---

### 6. **train/cnn.py** (1 thay Ä‘á»•i)

#### ÄÆ°á»ng dáº«n data_path (Line 41)
```python
# TRÆ¯á»šC:
data_path = os.path.join(project_root, 'data_processed', 'HDFS', 'session_data.pkl')

# SAU:
data_path = os.path.join(project_root, 'data_processed', 'session_data.pkl')
```

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c Chuáº©n

Sau khi sá»­a, cáº¥u trÃºc thÆ° má»¥c sáº½ nhÆ° sau:

```
LogDetection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ HDFS.log                    # Raw log file (1.5GB)
â”‚   â””â”€â”€ anomaly_label.csv           # Ground truth labels
â”‚
â”œâ”€â”€ data_processed/
â”‚   â”œâ”€â”€ HDFS_structured.csv         # Output tá»« parsers/drain.py
â”‚   â””â”€â”€ session_data.pkl            # Output tá»« detection/preprocess_data.py
â”‚
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ drain.py
â”‚   â””â”€â”€ drain3_state.bin            # Drain3 clustering state
â”‚
â”œâ”€â”€ detection/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ preprocess_data.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ transformer_model.pt
â”‚       â”œâ”€â”€ lstm_model.pt
â”‚       â””â”€â”€ cnn_model.pt
â”‚
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_transformer.py
â”‚   â”œâ”€â”€ lstm.py
â”‚   â””â”€â”€ cnn.py
â”‚
â”œâ”€â”€ communication/
â”‚   â””â”€â”€ server.py
â”‚
â””â”€â”€ main.py
```

---

## âœ… Workflow Chuáº©n Sau Khi Sá»­a

### 1. Parse Logs
```bash
conda activate IoT
python parsers/drain.py
# Output: data_processed/HDFS_structured.csv
```

### 2. Preprocess Data
```bash
python detection/preprocess_data.py
# Output: data_processed/session_data.pkl
```

### 3. Train Models
```bash
# Transformer
python train/train_transformer.py --model transformer --epochs 100

# LSTM
python train/lstm.py --epoches 100 --batch_size 1024

# CNN
python train/cnn.py --epoches 100 --batch_size 1024
```

### 4. Start Server
```bash
python communication/server.py
# Server sáº½ load:
# - data_processed/session_data.pkl
# - data/anomaly_label.csv
# - parsers/drain3_state.bin
# - detection/models/transformer_model.pt
```

---

## ğŸ¯ Kiá»ƒm Tra Sau Khi Sá»­a

Cháº¡y cÃ¡c lá»‡nh sau Ä‘á»ƒ kiá»ƒm tra:

```bash
# 1. Kiá»ƒm tra file tá»“n táº¡i
ls -lh data/anomaly_label.csv
ls -lh data/HDFS.log

# 2. Kiá»ƒm tra thÆ° má»¥c data_processed
ls -lh data_processed/

# 3. Test parse (náº¿u chÆ°a cÃ³ file)
conda activate IoT
python parsers/drain.py

# 4. Test preprocess
python detection/preprocess_data.py

# 5. Test server startup
python communication/server.py
# Ctrl+C Ä‘á»ƒ dá»«ng sau khi tháº¥y "Loaded ... model"
```

---

## ğŸ“ Ghi ChÃº Quan Trá»ng

1. **Táº¥t cáº£ Ä‘Æ°á»ng dáº«n Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a** Ä‘á»ƒ sá»­ dá»¥ng `os.path.join()` - tÆ°Æ¡ng thÃ­ch cáº£ Windows vÃ  Linux

2. **KhÃ´ng cÃ²n hardcode Ä‘Æ°á»ng dáº«n Windows** (backslash `\`)

3. **Táº¥t cáº£ Ä‘Æ°á»ng dáº«n Ä‘á»u relative** tá»« `project_root` - dá»… dÃ ng di chuyá»ƒn project

4. **MÃ´i trÆ°á»ng conda:** Nhá»› luÃ´n activate mÃ´i trÆ°á»ng `IoT` trÆ°á»›c khi cháº¡y:
   ```bash
   conda activate IoT
   ```

5. **File cáº§n cÃ³ trÆ°á»›c khi cháº¡y:**
   - `data/HDFS.log` (Ä‘Ã£ cÃ³ - 1.5GB)
   - `data/anomaly_label.csv` (Ä‘Ã£ cÃ³ - 18MB)

---

## ğŸš€ Tráº¡ng ThÃ¡i

- âœ… Táº¥t cáº£ Ä‘Æ°á»ng dáº«n Ä‘Ã£ Ä‘Æ°á»£c sá»­a
- âœ… Code tÆ°Æ¡ng thÃ­ch vá»›i Linux
- âœ… Cáº¥u trÃºc thÆ° má»¥c Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a
- âœ… Sáºµn sÃ ng Ä‘á»ƒ cháº¡y workflow hoÃ n chá»‰nh

**Há»‡ thá»‘ng giá» Ä‘Ã£ sáºµn sÃ ng!** ğŸ‰
